import jsonlines
import pandas as pd
import numpy as np
from transformers import AutoTokenizer
from sapie.models.embeddings.load_embeddings import EmbeddingLoader
from sapie.rag.retriever.faiss_retriever import get_faiss_db
# from sapie.rag.retriever.custom_bm25_retriever import BM25Retriever
from sapie.rag.retriever.nochain_bm25_retriever import BM25Retriever
# from sapie.rag.retriever.custom_faiss_retriever import FaissRetriever
from sapie.rag.retriever.nochain_faiss_retriever import FaissRetriever
from kiwipiepy import Kiwi


class HybridRetrieverChain:
    def __init__(self, config, save_csv=False):
        """
        Hybrid Retriever Chain (BM25 + FAISS)

        Args:
            config: ì„¤ì • ì •ë³´ (ì„ë² ë”© ëª¨ë¸, FAISS ê²½ë¡œ, í† í¬ë‚˜ì´ì € ê²½ë¡œ, JSONL ê²½ë¡œ í¬í•¨)
            save_csv (bool): CSV ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
        """
        self._validate_config(config)
        self.config = config
        self.save_csv = save_csv  # ğŸ”¹ CSV ì €ì¥ ì˜µì…˜

        self.bm25_config = {"k1": 1.5, "b": 0.75, "epsilon": 0.5}  # BM25 ì„¤ì •
        self.bm25_search_k = 5
        self.vectorstore_search_k = 5
        self.hybrid_search_k = 3  # ìµœì¢… ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜
        self.context_max_length = 8000  # ìµœì¢… ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
        self.rrf_score = 60  # RRF ì„¤ì •ê°’

        self.kiwi = Kiwi()  # í˜•íƒœì†Œ ë¶„ì„ê¸°
        self.embedding_loader = EmbeddingLoader(config_file="sapie/configs/config.json")

        # BM25 ë° FAISS ì´ˆê¸°í™”
        self._initialize_retrievers()

    def _validate_config(self, config):
        """ì„¤ì • íŒŒì¼ì—ì„œ í•„ìˆ˜ í•„ë“œ í™•ì¸"""
        required_fields = ["embedding_model_path", "faiss_path", "tokenizer_path", "jsonl_path"]
        missing_fields = [field for field in required_fields if field not in config]
        if missing_fields:
            raise ValueError(f"(hybrid_search_chain.py) Missing required configuration fields: {', '.join(missing_fields)}")

    def _initialize_retrievers(self):
        """BM25 ë° FAISS ê²€ìƒ‰ê¸° ì´ˆê¸°í™”"""
        train_data = self.read_jsonl(self.config["jsonl_path"])
        corpus = [data["combined_metadata"] for data in train_data]

        # BM25 ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        self.bm25_retriever = BM25Retriever(
            corpus,
            k=self.bm25_search_k,
            preprocess_func=self.kiwi_tokenize,
            bm25_params=self.bm25_config,
        )

        # FAISS ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        embeddings = self.embedding_loader.get_embedding_model()
        vectorstore = get_faiss_db(embeddings, self.config["faiss_path"])

        self.faiss_retriever = FaissRetriever(
            vectorstore, 
            k=self.vectorstore_search_k
        )

    def _save_to_csv(self, df, filename):
        """CSV ì €ì¥ (save_csv=Trueì¼ ë•Œë§Œ ì‹¤í–‰)"""
        if not self.save_csv:
            return
        try:
            save_path = f"/home/jskim/data_js/test_241226/sapie/data/csv_results/{filename}"
            df.to_csv(save_path, index=False, encoding="utf-8")
            print(f"âœ… CSV ì €ì¥ ì™„ë£Œ: {save_path}")
        except Exception as e:
            print(f"ğŸš¨ CSV ì €ì¥ ì˜¤ë¥˜: {str(e)}")

    def kiwi_tokenize(self, text):
        """í˜•íƒœì†Œ ë¶„ì„ì„ ì‚¬ìš©í•œ í† í°í™”"""
        return [token.form for token in self.kiwi.tokenize(text)]

    def read_jsonl(self, path):
        """JSONL íŒŒì¼ ì½ê¸°"""
        with jsonlines.open(path) as f:
            return [line for line in f]

    def calculate_rrf_scores(self, bm25_results, faiss_results):
        """BM25 & FAISS ê²°ê³¼ë¥¼ RRF ë°©ì‹ìœ¼ë¡œ ê²°í•©"""
        bm25_df = bm25_results.sort_values("score", ascending=False).reset_index(drop=True)
        faiss_df = faiss_results.sort_values("score", ascending=True).reset_index(drop=True)

        # RRF ì ìˆ˜ ê³„ì‚°
        bm25_df["new_scores_RRF"] = 1 / ((bm25_df.index + 5) + self.rrf_score)
        faiss_df["new_scores_RRF"] = 1 / ((faiss_df.index + 1) + self.rrf_score)

        combined_df = pd.concat([bm25_df, faiss_df]).sort_values("new_scores_RRF", ascending=False).reset_index(drop=True)
        self._save_to_csv(combined_df, "combined_results.csv")  # ğŸ”¹ RRF ê²°ê³¼ CSV ì €ì¥

        top_n_results = combined_df.drop_duplicates(subset="text").sort_values("new_scores_RRF", ascending=False).reset_index(drop=True)

        # ê²€ìƒ‰ ê¸¸ì´ ì œí•œ
        total_text_length = top_n_results.head(self.hybrid_search_k)["text_length"].sum()
        print(f"ğŸ“ ì´ ë¬¸ìì—´ ê¸¸ì´: {total_text_length}")

        cumulative_sum = np.cumsum(top_n_results["text_length"])
        first_n = (cumulative_sum >= self.context_max_length).argmax() + 1
        if first_n == 0 or first_n == 1:
            first_n = len(cumulative_sum)
        print(f"ğŸ“Œ ì„ íƒëœ ë¬¸ì„œ ê°œìˆ˜: {first_n}")
        top_n_results = top_n_results.head(first_n)

        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        result_str = ""
        current_length = 0
        used_indices = []
        for i in range(len(top_n_results)):
            document = top_n_results.loc[i]["text"]
            score = top_n_results.loc[i]["new_scores_RRF"]

            document_str = f"{document} ê´€ë ¨ì„±: {score}\n\n"
            new_length = current_length + len(document_str)
            if new_length > self.context_max_length:
                break

            result_str += document_str
            current_length = new_length
            used_indices.append(i)

        # ì‚¬ìš©ëœ ê²°ê³¼ CSV ì €ì¥
        used_results = top_n_results.iloc[used_indices]
        self._save_to_csv(used_results, "used_results.csv")

        return result_str

    def retrieve_hybrid_results(self, query):
        """BM25 + FAISS í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰"""
        bm25_results = self.bm25_retriever.retrieve(query)
        faiss_results = self.faiss_retriever.retrieve(query)

        # RRF ê¸°ë°˜ ìµœì  ê²°ê³¼ ê³„ì‚°
        final_context = self.calculate_rrf_scores(bm25_results, faiss_results)
        return final_context
